{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîê Machine Learning for Malicious URL / QR Detection\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In today's world, the modern internet is densely filled with Uniform Resource Locators (URLs) that point to countless resources across popular social communication platforms like WhatsApp, Instagram, and Messenger. Users can easily share links and QR codes for quick access to information. However, these platforms can be misused to spread **malicious content** through deceptive URLs or QR codes, leading to significant risks to user privacy and data security.\n",
    "\n",
    "Attackers often perform **social media phishing** by utilizing deceptive URLs and QR codes to trick users into clicking or scanning, thereby injecting malware virus by redirecting them to harmful websites. This significantly leads to **malware infections, data breaches, and financial losses**.\n",
    "\n",
    "This project aims to build a machine learning model that integrates detailed feature extraction (domain_age, tinyURL, web_traffic, DNS record) to improve overall static detection of malicious URLs.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Objectives\n",
    "\n",
    "1. ‚úÖ To identify URL patterns (lexical, domain-based) indicative of malicious sites\n",
    "2. ‚úÖ To evaluate and compare the performance of different ML models for malicious URLs classification\n",
    "3. ‚úÖ To develop a ML-based model capable of detecting phishing attempts based on URL patterns reliably\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset: LegitPhish\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Total URLs** | 101,219 |\n",
    "| **Phishing URLs** | 62.9% |\n",
    "| **Legitimate URLs** | 37.1% |\n",
    "| **Initial Features** | 18 |\n",
    "\n",
    "**Data Source:** URLHaus database and other well-known repositories of malicious websites, as well as legitimate URLs collected from reputable sources like Wikipedia and Stack Overflow.\n",
    "\n",
    "---\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Data Pre-processing\n",
    "- Data Collection\n",
    "- Data Cleaning\n",
    "- Detailed Feature Extraction\n",
    "- Data Splitting (80/20)\n",
    "\n",
    "### Machine Learning (Binary Classification)\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "### Evaluation Metrics\n",
    "- F1-Score\n",
    "- Precision\n",
    "- AUC-ROC\n",
    "- Recall\n",
    "- Confusion Matrix\n",
    "- Accuracy\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. Potpelwar, R. S., Kulkarni, U. V., & Waghmare, J. M. (2025). LegitPhish: A large-scale annotated dataset for URL-based phishing detection. Data in Brief, 63, 111972. https://doi.org/10.1016/j.dib.2025.111972\n",
    "2. Xuan, C. D., Dinh, H., & Victor, T. (2020). Malicious URL Detection based on Machine Learning. International Journal of Advanced Computer Science and Applications, 11(1). https://doi.org/10.14569/ijacsa.2020.0110119\n",
    "3. Aryan Nandu, Sosa, J., Pant, Y., Panchal, Y., & Sayyad, S. (2024). Malicious URL Detection Using Machine Learning. 1‚Äì6. https://doi.org/10.1109/asiancon62057.2024.10837752\n",
    "\n",
    "---\n",
    "\n",
    "## Authors\n",
    "\n",
    "| Name | Student ID |\n",
    "|------|------------|\n",
    "| YIM WJUN JUN | 24201054 |\n",
    "| RICHIE TEOH | 24088171 |\n",
    "| ELMER LEE JIA ZHAO | 24082366 |\n",
    "| ANGELINE TAN JIE LIN | 24084444 |\n",
    "| NICOLE CHUNG SYN TUNG | 24073625 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Data Collection\n",
    "\n",
    "This section loads the LegitPhish dataset containing URLs with pre-extracted features for phishing detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import urllib\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import socket\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial dataset\n",
    "github_dataset = 'https://raw.githubusercontent.com/Elmer2408/WQD7006_Machine-learning-of-Malicious-URLs-Detection/main/url_features_extracted1.csv'\n",
    "df = pd.read_csv(github_dataset)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INITIAL DATASET LOADED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Samples: {df.shape[0]:,}\")\n",
    "print(f\"Total Features: {df.shape[1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature descriptions\n",
    "descriptions = {\n",
    "    \"url\": \"The full URL string (original data).\",\n",
    "    \"url_length\": \"Total number of characters in the URL.\",\n",
    "    \"has_ip_address\": \"Binary flag (1/0): whether the URL contains an IP address.\",\n",
    "    \"dot_count\": \"Number of . characters in the URL.\",\n",
    "    \"https_flag\": \"Binary flag (1/0): whether the URL uses HTTPS.\",\n",
    "    \"url_entropy\": \"Shannon entropy of the URL string ‚Äì higher values indicate more randomness.\",\n",
    "    \"token_count\": \"Number of tokens/words in the URL.\",\n",
    "    \"subdomain_count\": \"Number of subdomains in the URL.\",\n",
    "    \"query_param_count\": \"Number of query parameters (after ?).\",\n",
    "    \"tld_length\": \"Length of the Top-Level Domain (e.g., 'com' = 3).\",\n",
    "    \"path_length\": \"Length of the path part after the domain.\",\n",
    "    \"has_hyphen_in_domain\": \"Binary flag (1/0): whether the domain contains a hyphen (-).\",\n",
    "    \"number_of_digits\": \"Total number of numeric characters in the URL.\",\n",
    "    \"tld_popularity\": \"Binary flag (1/0): whether the TLD is popular.\",\n",
    "    \"suspicious_file_extension\": \"Binary flag (1/0): indicates if the URL ends with suspicious extensions (e.g., .exe, .zip).\",\n",
    "    \"domain_name_length\": \"Length of the domain name.\",\n",
    "    \"percentage_numeric_chars\": \"Percentage of numeric characters in the URL.\",\n",
    "    \"classlabel\": \"Target label: 1 = Legitimate, 0 = Phishing.\",\n",
    "}\n",
    "\n",
    "# Create metadata table\n",
    "metadata = pd.DataFrame({\n",
    "    \"Column Name\": df.columns,\n",
    "    \"Data Type\": df.dtypes.values,\n",
    "    \"Non-Null Count\": df.notnull().sum().values,\n",
    "    \"Null Count\": df.isnull().sum().values,\n",
    "    \"Unique Values\": df.nunique().values,\n",
    "    \"Sample Values\": [df[col].dropna().unique()[:3] for col in df.columns],\n",
    "    \"Description\": [descriptions[col] for col in df.columns]\n",
    "})\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET METADATA\")\n",
    "print(\"=\"*60)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Data Cleaning\n",
    "\n",
    "This section handles missing values, duplicates, and data type conversions to prepare the dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Check\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate URL entries: {duplicates}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"\\nMissing Values per Column:\")\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values found\")\n",
    "print(f\"\\nTotal Missing in Target (classlabel): {df['classlabel'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset\n",
    "df_cleaned = df.copy()\n",
    "df_cleaned = df_cleaned.dropna(how='any')  # Remove rows with null values\n",
    "df_cleaned['classlabel'] = df_cleaned['classlabel'].astype(int)  # Convert float64 to int64\n",
    "df_cleaned.columns = df_cleaned.columns.str.lower()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AFTER DATA CLEANING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original Dataset Size: {df.shape[0]:,}\")\n",
    "print(f\"Cleaned Dataset Size: {df_cleaned.shape[0]:,}\")\n",
    "print(f\"Rows Removed: {df.shape[0] - df_cleaned.shape[0]:,}\")\n",
    "\n",
    "# Updated metadata after cleaning\n",
    "metadata_cleaned = pd.DataFrame({\n",
    "    \"Column Name\": df_cleaned.columns,\n",
    "    \"Data Type\": df_cleaned.dtypes.values,\n",
    "    \"Non-Null Count\": df_cleaned.notnull().sum().values,\n",
    "    \"Null Count\": df_cleaned.isnull().sum().values,\n",
    "    \"Unique Values\": df_cleaned.nunique().values,\n",
    "    \"Sample Values\": [df_cleaned[col].dropna().unique()[:3] for col in df_cleaned.columns],\n",
    "    \"Description\": [descriptions[col] for col in df_cleaned.columns]\n",
    "})\n",
    "\n",
    "metadata_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Detailed Feature Extraction\n",
    "\n",
    "This section defines additional feature extraction functions for HTML, JavaScript, and domain-based features. These functions can be used for real-time URL analysis.\n",
    "\n",
    "**Note:** For this experiment, we use a pre-extracted dataset to avoid API rate limits and long processing times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction Functions\n",
    "\n",
    "def DNSRecord(url):\n",
    "    \"\"\"\n",
    "    Check if the domain has a valid DNS record.\n",
    "    Returns: 1 = Legitimate (DNS exists), 0 = Phishing (No DNS)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hostname = urlparse(url).netloc\n",
    "        if ':' in hostname:\n",
    "            hostname = hostname.split(':')[0]\n",
    "        if not hostname:\n",
    "            return 0\n",
    "        try:\n",
    "            socket.gethostbyname(hostname)\n",
    "            return 1\n",
    "        except socket.gaierror:\n",
    "            return 0\n",
    "        except Exception:\n",
    "            return 0\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def iframe(response):\n",
    "    \"\"\"\n",
    "    Check if the webpage contains iframe tags (potential phishing indicator).\n",
    "    Returns: 1 = Contains iframe, 0 = No iframe\n",
    "    \"\"\"\n",
    "    if response == \"\":\n",
    "        return 0\n",
    "    else:\n",
    "        if re.findall(r\"<iframe\", response):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "def mouseOver(response):\n",
    "    \"\"\"\n",
    "    Check if the webpage uses onmouseover events (potential phishing technique).\n",
    "    Returns: 0 = Contains onmouseover (suspicious), 1 = No onmouseover\n",
    "    \"\"\"\n",
    "    if response == \"\":\n",
    "        return 0\n",
    "    else:\n",
    "        if re.findall(r\"onmouseover\", response):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "\n",
    "def rightClick(response):\n",
    "    \"\"\"\n",
    "    Check if the webpage disables right-click (potential phishing technique).\n",
    "    Returns: 1 = Right-click disabled, 0 = Normal\n",
    "    \"\"\"\n",
    "    if response == \"\":\n",
    "        return 0\n",
    "    else:\n",
    "        if re.findall(r\"event.button ?== ?2\", response):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "def forwarding(url):\n",
    "    \"\"\"\n",
    "    Check the number of redirects for a URL.\n",
    "    Returns: 1 = Legitimate (‚â§2 redirects), 0 = Suspicious (>2 redirects)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(url, headers=headers, timeout=5)\n",
    "        redirect_count = len(response.history)\n",
    "        if redirect_count <= 2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "\n",
    "print(\"‚úÖ Feature extraction functions defined successfully!\")\n",
    "print(\"\\nAvailable functions:\")\n",
    "print(\"  - DNSRecord(url): Check DNS record existence\")\n",
    "print(\"  - iframe(response): Detect iframe tags\")\n",
    "print(\"  - mouseOver(response): Detect onmouseover events\")\n",
    "print(\"  - rightClick(response): Detect right-click blocking\")\n",
    "print(\"  - forwarding(url): Count URL redirects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the complete dataset with pre-extracted features\n",
    "github_dataset = 'https://raw.githubusercontent.com/Elmer2408/WQD7006_Machine-learning-of-Malicious-URLs-Detection/main/urldata_with_features_complete.csv'\n",
    "df_extract = pd.read_csv(github_dataset)\n",
    "df_extract.columns = df_extract.columns.str.lower()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPLETE DATASET WITH EXTRACTED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total URLs: {df_extract.shape[0]:,}\")\n",
    "print(f\"Total Features: {df_extract.shape[1]}\")\n",
    "print(f\"\\nFeatures: {df_extract.columns.tolist()}\")\n",
    "df_extract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "This section explores the dataset structure, class distribution, feature correlations, and distributions to understand the data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dataset Overview\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total URLs: {df_extract.shape[0]:,}\")\n",
    "print(f\"Total Features: {df_extract.shape[1]}\")\n",
    "print(f\"\\nColumn Names:\\n{df_extract.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution\n",
    "print(\"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class_counts = df_extract['classlabel'].value_counts()\n",
    "class_percent = df_extract['classlabel'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"\\nPhishing URLs (0): {class_counts[0]:,} ({class_percent[0]:.1f}%)\")\n",
    "print(f\"Legitimate URLs (1): {class_counts[1]:,} ({class_percent[1]:.1f}%)\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie Chart\n",
    "colors = ['#dc3545', '#28a745']\n",
    "axes[0].pie(class_counts, labels=['Phishing (0)', 'Legitimate (1)'], autopct='%1.1f%%',\n",
    "            colors=colors, explode=(0.02, 0.02), startangle=90)\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar Chart\n",
    "ax = sns.countplot(x='classlabel', data=df_extract, palette=['#dc3545', '#28a745'], ax=axes[1])\n",
    "axes[1].set_xticklabels(['Phishing (0)', 'Legitimate (1)'])\n",
    "axes[1].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class Label')\n",
    "axes[1].set_ylabel('Count')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"=\"*60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "df_extract.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Correlation Heatmap\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE CORRELATION HEATMAP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "numeric_df = df_extract.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            fmt='.2f', linewidths=0.5, annot_kws={'size': 8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Correlation with Target\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE CORRELATION WITH TARGET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "target_correlation = correlation_matrix['classlabel'].drop('classlabel').sort_values(ascending=False)\n",
    "print(\"\\nFeatures sorted by correlation with classlabel:\\n\")\n",
    "print(target_correlation.round(4))\n",
    "\n",
    "# Visualize correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['#28a745' if x > 0 else '#dc3545' for x in target_correlation.values]\n",
    "target_correlation.plot(kind='barh', color=colors)\n",
    "plt.title('Feature Correlation with Target (ClassLabel)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Features')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Features Analysis\n",
    "# Based on project poster: url_length, has_ip_address, https_flag, subdomain_count, url_entropy\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY FEATURES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "key_features = ['url_length', 'has_ip_address', 'https_flag', 'subdomain_count', 'url_entropy']\n",
    "print(f\"5 Key Features: {key_features}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    sns.boxplot(x='classlabel', y=feature, data=df_extract, ax=axes[idx],\n",
    "                palette=['#dc3545', '#28a745'])\n",
    "    axes[idx].set_xticklabels(['Phishing (0)', 'Legitimate (1)'])\n",
    "    axes[idx].set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "axes[-1].set_visible(False)\n",
    "\n",
    "plt.suptitle('Key Features Distribution by Class', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Distribution by Class (All Features)\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE DISTRIBUTION BY CLASS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "feature_cols = [col for col in numeric_df.columns if col not in ['classlabel']]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_cols[:20]):\n",
    "    sns.boxplot(x='classlabel', y=col, data=df_extract, ax=axes[idx], palette=['#dc3545', '#28a745'])\n",
    "    axes[idx].set_title(f'{col}', fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_xlabel('')\n",
    "    axes[idx].set_xticklabels(['Phishing', 'Legitimate'])\n",
    "\n",
    "for idx in range(len(feature_cols[:20]), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Feature Distribution by Class (0=Phishing, 1=Legitimate)', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Data Splitting\n",
    "\n",
    "This section separates features and target variables, then splits the data into training (80%) and testing (20%) sets with stratification to maintain class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df_extract.drop(columns=['classlabel', 'url'])\n",
    "y = df_extract['classlabel']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE AND TARGET SEPARATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Features Shape (X): {X.shape}\")\n",
    "print(f\"Target Shape (y): {y.shape}\")\n",
    "print(f\"Number of Features: {X.shape[1]}\")\n",
    "print(f\"\\nFeature Columns:\\n{X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (80% Training, 20% Testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAIN-TEST SPLIT (80/20)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training Set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Testing Set: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nTraining Class Distribution:\")\n",
    "print(f\"  Phishing (0): {(y_train == 0).sum():,}\")\n",
    "print(f\"  Legitimate (1): {(y_train == 1).sum():,}\")\n",
    "print(f\"\\nTesting Class Distribution:\")\n",
    "print(f\"  Phishing (0): {(y_test == 0).sum():,}\")\n",
    "print(f\"  Legitimate (1): {(y_test == 1).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE SCALING (STANDARDIZATION)\")\n",
    "print(\"=\"*60)\n",
    "print(\"StandardScaler applied: mean=0, std=1\")\n",
    "print(\"\\nSample of scaled training data:\")\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Modeling (Binary Classification)\n",
    "\n",
    "This section trains four machine learning models as specified in the project methodology:\n",
    "- **Logistic Regression**: A linear model for binary classification\n",
    "- **Random Forest**: An ensemble of decision trees\n",
    "- **XGBoost**: Extreme Gradient Boosting algorithm\n",
    "- **LightGBM**: Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install lightgbm xgboost --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define 4 models as per project methodology\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss', verbosity=0),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MACHINE LEARNING MODELS\")\n",
    "print(\"=\"*60)\n",
    "for i, model_name in enumerate(models.keys(), 1):\n",
    "    print(f\"{i}. {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models and collect results\n",
    "results = []\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL TRAINING IN PROGRESS...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n‚ñ∂ Training {model_name}...\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Calculate all evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': roc_auc\n",
    "    })\n",
    "\n",
    "    print(f\"  ‚úì Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f} | AUC: {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL MODELS TRAINED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Evaluation Metrics\n",
    "\n",
    "This section evaluates and compares all trained models using the following metrics:\n",
    "- **Accuracy**: Overall correctness of predictions\n",
    "- **Precision**: Ratio of true positives to all positive predictions\n",
    "- **Recall**: Ratio of true positives to all actual positives\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **AUC-ROC**: Area under the Receiver Operating Characteristic curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance Comparison Table\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='F1-Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Model Performance Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Grouped bar chart for all metrics\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.15\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[0].bar(x + i*width, results_df[metric], width, label=metric, color=colors[i])\n",
    "\n",
    "axes[0].set_xlabel('Model', fontsize=12)\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x + width * 2)\n",
    "axes[0].set_xticklabels(results_df['Model'], rotation=15, ha='right')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].set_ylim(0, 1.1)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# AUC-ROC comparison\n",
    "colors_models = ['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728']\n",
    "bars = axes[1].barh(results_df['Model'], results_df['AUC-ROC'], color=colors_models, edgecolor='black')\n",
    "axes[1].set_title('AUC-ROC Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('AUC-ROC Score')\n",
    "axes[1].set_xlim(0, 1.1)\n",
    "for i, (bar, v) in enumerate(zip(bars, results_df['AUC-ROC'])):\n",
    "    axes[1].text(v + 0.01, bar.get_y() + bar.get_height()/2, f'{v:.4f}', va='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model Summary\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üèÜ BEST PERFORMING MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n   Model:     {best_model_name}\")\n",
    "print(f\"\\n   Accuracy:  {results_df.iloc[0]['Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {results_df.iloc[0]['Precision']:.4f}\")\n",
    "print(f\"   Recall:    {results_df.iloc[0]['Recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {results_df.iloc[0]['F1-Score']:.4f}\")\n",
    "print(f\"   AUC-ROC:   {results_df.iloc[0]['AUC-ROC']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Confusion Matrix\n",
    "\n",
    "The confusion matrix visualizes the performance of each classification model by showing:\n",
    "- **True Positives (TP)**: Correctly predicted legitimate URLs\n",
    "- **True Negatives (TN)**: Correctly predicted phishing URLs\n",
    "- **False Positives (FP)**: Phishing URLs incorrectly predicted as legitimate\n",
    "- **False Negatives (FN)**: Legitimate URLs incorrectly predicted as phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_name, model) in enumerate(models.items()):\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Phishing (0)', 'Legitimate (1)'])\n",
    "    disp.plot(cmap='Blues', ax=axes[idx], colorbar=False)\n",
    "    axes[idx].set_title(f'{model_name}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Confusion Matrix - All Models', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Classification Report for Best Model\n",
    "print(\"=\"*60)\n",
    "print(f\"CLASSIFICATION REPORT - {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Phishing (0)', 'Legitimate (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9. AUC-ROC Curve\n",
    "\n",
    "The ROC (Receiver Operating Characteristic) curve plots the True Positive Rate against the False Positive Rate at various threshold settings. The AUC (Area Under the Curve) measures the model's ability to distinguish between classes:\n",
    "- **AUC = 1.0**: Perfect classifier\n",
    "- **AUC = 0.5**: Random classifier (no discrimination)\n",
    "- **AUC > 0.9**: Excellent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728']\n",
    "line_styles = ['-', '--', '-.', ':']\n",
    "\n",
    "for (model_name, model), color, ls in zip(models.items(), colors, line_styles):\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.4f})',\n",
    "             linewidth=2.5, color=color, linestyle=ls)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Random Classifier (AUC = 0.5)')\n",
    "plt.fill_between([0, 1], [0, 1], alpha=0.1, color='gray')\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - Model Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 10. Feature Importance Analysis\n",
    "\n",
    "This section identifies the most important features for predicting phishing URLs. Feature importance helps understand which URL characteristics are most indicative of malicious intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': models['Random Forest'].feature_importances_\n",
    "}).sort_values(by='Importance', ascending=True)\n",
    "\n",
    "axes[0, 0].barh(rf_importance['Feature'], rf_importance['Importance'], color='#2ca02c')\n",
    "axes[0, 0].set_xlabel('Importance Score')\n",
    "axes[0, 0].set_title('Feature Importance - Random Forest', fontsize=12, fontweight='bold')\n",
    "\n",
    "# XGBoost Feature Importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': models['XGBoost'].feature_importances_\n",
    "}).sort_values(by='Importance', ascending=True)\n",
    "\n",
    "axes[0, 1].barh(xgb_importance['Feature'], xgb_importance['Importance'], color='#ff7f0e')\n",
    "axes[0, 1].set_xlabel('Importance Score')\n",
    "axes[0, 1].set_title('Feature Importance - XGBoost', fontsize=12, fontweight='bold')\n",
    "\n",
    "# LightGBM Feature Importance\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': models['LightGBM'].feature_importances_\n",
    "}).sort_values(by='Importance', ascending=True)\n",
    "\n",
    "axes[1, 0].barh(lgb_importance['Feature'], lgb_importance['Importance'], color='#d62728')\n",
    "axes[1, 0].set_xlabel('Importance Score')\n",
    "axes[1, 0].set_title('Feature Importance - LightGBM', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Logistic Regression Coefficients\n",
    "lr_coef = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': np.abs(models['Logistic Regression'].coef_[0])\n",
    "}).sort_values(by='Coefficient', ascending=True)\n",
    "\n",
    "axes[1, 1].barh(lr_coef['Feature'], lr_coef['Coefficient'], color='#1f77b4')\n",
    "axes[1, 1].set_xlabel('Absolute Coefficient')\n",
    "axes[1, 1].set_title('Feature Importance - Logistic Regression', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Feature Importance Analysis - All Models', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Most Important Features\n",
    "print(\"=\"*60)\n",
    "print(\"TOP 10 MOST IMPORTANT FEATURES (Random Forest)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "top_10_rf = rf_importance.sort_values(by='Importance', ascending=False).head(10)\n",
    "for i, (idx, row) in enumerate(top_10_rf.iterrows(), 1):\n",
    "    print(f\"  {i:2}. {row['Feature']:25} : {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 11. Summary & Conclusion\n",
    "\n",
    "This section summarizes the findings from the machine learning experiment for malicious URL detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìä PROJECT SUMMARY: Machine Learning for Malicious URL/QR Detection\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÅ DATASET: LegitPhish\")\n",
    "print(f\"   ‚Ä¢ Total URLs: {df_extract.shape[0]:,}\")\n",
    "print(f\"   ‚Ä¢ Phishing URLs: {(df_extract['classlabel'] == 0).sum():,} ({(df_extract['classlabel'] == 0).sum()/len(df_extract)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Legitimate URLs: {(df_extract['classlabel'] == 1).sum():,} ({(df_extract['classlabel'] == 1).sum()/len(df_extract)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Features Used: {X.shape[1]}\")\n",
    "\n",
    "print(f\"\\nü§ñ MODELS EVALUATED:\")\n",
    "for i, model in enumerate(models.keys(), 1):\n",
    "    print(f\"   {i}. {model}\")\n",
    "\n",
    "print(f\"\\nüìà BEST MODEL: {best_model_name}\")\n",
    "print(f\"   ‚Ä¢ Accuracy:  {results_df.iloc[0]['Accuracy']:.4f} ({results_df.iloc[0]['Accuracy']*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Precision: {results_df.iloc[0]['Precision']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall:    {results_df.iloc[0]['Recall']:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {results_df.iloc[0]['F1-Score']:.4f}\")\n",
    "print(f\"   ‚Ä¢ AUC-ROC:   {results_df.iloc[0]['AUC-ROC']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ TOP 5 PREDICTIVE FEATURES:\")\n",
    "top_5 = rf_importance.sort_values(by='Importance', ascending=False).head(5)\n",
    "for i, (idx, row) in enumerate(top_5.iterrows(), 1):\n",
    "    print(f\"   {i}. {row['Feature']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Model successfully developed for detecting phishing URLs!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Key Findings\n",
    "\n",
    "1. **Dataset Characteristics**: The LegitPhish dataset contains over 100,000 URLs with a class imbalance (62.9% phishing vs 37.1% legitimate).\n",
    "\n",
    "2. **Model Performance**: All four models achieved high accuracy in detecting malicious URLs, with ensemble methods (Random Forest, XGBoost, LightGBM) generally outperforming Logistic Regression.\n",
    "\n",
    "3. **Important Features**: URL entropy, URL length, and domain-based features proved to be the most predictive indicators of phishing attempts.\n",
    "\n",
    "4. **Practical Application**: The trained model can be deployed for real-time URL scanning to protect users from phishing attacks on social media platforms.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Future Work\n",
    "\n",
    "- Implement real-time URL feature extraction for live predictions\n",
    "- Add QR code scanning and URL extraction functionality\n",
    "- Deploy the model as a web API or browser extension\n",
    "- Continuously update the model with new phishing patterns\n",
    "\n",
    "---\n",
    "\n",
    "**¬© 2025 WQD7006 Machine Learning Project - Universiti Malaya**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
